{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "tags": [
     "frontmatter"
    ]
   },
   "source": [
    "show_input: hide \n",
    "github: https://github.com/sandiegodata/covid19/blob/master/Notebooks/WhyNotTesting.ipynb\n",
    "featured_image: 510 \n",
    "authors: \n",
    "- email: eric@civicknowledge.com \n",
    "name: Eric Busboom \n",
    "organization: Civic Knowledge \n",
    "type: Analyst \n",
    "tags: \n",
    "- covid19 \n",
    "categories: \n",
    "- Health\n",
    "identifier: f30be0f4-5e12-476a-9d58-9763f9f8ab9c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Title"
    ]
   },
   "source": [
    "## Why Not More Testing? The Effects of False Positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Description"
    ]
   },
   "source": [
    "The US government has been widely criticized for its failure to test as many of its citizens for COVID-19 infections as other countries. But is there a good explaination for the lack of testing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Install required packages\n",
    "#!{sys.executable} -mpip -q install matplotlib seaborn statsmodels pandas publicdata metapack\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import metapack as mp\n",
    "import rowgenerators as rg\n",
    "import publicdata as pub\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the world became more aware of the threat posed by COVID-19 in February 2020, US media began to draw attention to the disparity between the extent of testing being done in other countries versus the United States. The CDC released [fairly restrictive guidelines](https://www.cdc.gov/coronavirus/2019-ncov/hcp/clinical-criteria.html) for what conditions qualified a patient for a lab test for COVID-19 infections, and many media outlets criticized the US CDC for being unprepared to test for the virus. \n",
    "\n",
    "Criticism intensified when the first version of tests created by the CDC [proved to be unreliable](https://www.forbes.com/sites/rachelsandler/2020/03/02/how-the-cdc-botched-its-initial-coronavirus-response-with-faulty-tests/#5bbf1d50670e). But there are important considerations that these reports have largely ignored, the most important of which is the false positive and false negative rates of the tests, which can produce results that are worse than useless when the prevalence of the condition — the percentage of people who are infected — is very low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every test — for nearly any sort of test — has an error rate: false positives and false negatives. False negatives are fairly easy to understand. If a 1,000 women who have breast cancer take a test that has a false positive rate of 1%, the test will report that 999 of them have cancer, and 1 who does not, even though she actually does.\n",
    "\n",
    "The false positive rate is trickier, because it is multipled not by the number of women who have cancer, but by the number of women who take the test. If the situation is that a large number of women are tested, but few have cancer, the test can report many more false positives than women who actually have cancer. \n",
    "\n",
    "There is evidence that the tests for the COVID-19 virus have a false positive rate large enough that if a large number of people are tested when the prevalence of COVID-19 infections are small, most of the reported positives are false positives. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primer on False Positives and Negatives\n",
    "\n",
    "Research related to epidemiological tests typically does not report the false positive rate directly; instead it reports two parameters, the Selectivity and Specificity. [Wikipedia has an excellent article](https://en.wikipedia.org/wiki/Sensitivity_and_specificity) describing these parameters and how they related to false positive and false negative rates.  The most important part of the Wikipedia article to understand is the table in the [worked example](https://en.wikipedia.org/wiki/Sensitivity_and_specificity#Worked_example). When a test is administered, there are four possible outcomes. The test can return a positive result, which can be a true positive or a false positive, or it can return a negative result, which is a true negative or a false negative. If you organize those posibilities by what is the true condition ( does the patient have the vius or not ):\n",
    "\n",
    "* Patient has virus\n",
    " * True Positive ($\\mathit{TP}$)\n",
    " * False negative ($\\mathit{FN}$)\n",
    "* Patient does not have virus\n",
    " * True Negative ($\\mathit{TN}$)\n",
    " * False Positive.  ($\\mathit{FP}$)\n",
    "\n",
    "In the Wikipedia worked example table:\n",
    "\n",
    "* The number of people who do have the virus is $\\mathit{TP}+\\mathit{FN}$, the true positives plus the false negatives, which are the cases that should have been reported positive, but were not. \n",
    "* The number of people who do not have the virus is $\\mathit{TN}+\\mathit{FP}$, the true negatives and the false positives, which are the cases should have been reported positive, but were not. \n",
    "\n",
    "The values of Sensitivity and Specificity are defined as: \n",
    "\n",
    "$$\\begin{array}{ll}\n",
    "Sn = \\frac{\\mathit{TP}}{\\mathit{TP} + \\mathit{FN}} & \\text{True positives outcomes divided by all positive conditions} \\tag{1}\\label{eq1}\\\\ \n",
    "Sp = \\frac{\\mathit{TN}}{\\mathit{FP} + \\mathit{TN}} & \\text{True negatives outcomes divided by all negative conditions}\\\\ \n",
    "\\end{array}$$\n",
    "\n",
    "We want to know the number of false positives($\\mathit{FP}$) given the number of positive conditions ($\\mathit{TP}+\\mathit{FN}$) and the total number of tests. To compute these, we need to have some more information about the number of people tested, and how common the disease is: \n",
    "\n",
    "* Total test population $P$, the number of people being tested, which equals $\\mathit{TP}+\\mathit{FP}+\\mathit{FN}+\\mathit{TN}$\n",
    "* The prevalence $p$, the population rate of positive condition. \n",
    "\n",
    "We can do a little math to get: \n",
    "\n",
    "$$\\begin{array}{ll}\n",
    "\\mathit{TP} = Pp\\mathit{Sn} & \\text{}\\\\ \n",
    "\\mathit{FP} = P(1-p)(1-\\mathit{Sp}) \\text{}\\\\ \n",
    "\\mathit{TN} = P(1-p)\\mathit{Sp} & \\text{}\\\\ \n",
    "\\mathit{FN} = Pp(1-\\mathit{Sn})& \\text{}\\\\ \n",
    "\\end{array}$$\n",
    "\n",
    "You can see examples of these equations worked out in the third line in the red and green cells of the [Worked Example](https://en.wikipedia.org/wiki/Sensitivity_and_specificity#Worked_example) on the Sensitivity and Specificity Wikipedia page. \n",
    "\n",
    "It is important to note that when these four values are used to calculate $\\mathit{Sp}$ and $\\mathit{Sn}$, the population value $P$ cancels out, so $\\mathit{Sp}$ and $\\mathit{Sn}$ do not depend on the number of people tested. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the interesting questions when test results are reported is \"What percentage of the positive results are true positives?\" This is a particularly important question for the COVID-19 pandemic because there are a lot of reports that most people with the virus are asymptomatic. Are they really asymptomatic, or just false positives?\n",
    "\n",
    "The metric we're interested here is the portion of positive results that are true positives, the positive predictive value, $\\mathit{PPV}$:\n",
    "\n",
    "$$\\mathit{PPV} = \\frac{\\mathit{TP} }{ \\mathit{TP} +\\mathit{FP}  } $$\n",
    "\n",
    "Which expands to:\n",
    "\n",
    "$$\\mathit{PPV} = \\frac{p\\mathit{Sn} }{ p\\mathit{Sn} + (1-p)(1-\\mathit{Sp})  }\\tag{2}\\label{eq2} $$\n",
    "\n",
    "It is important to note that $\\mathit{PPV}$ is not dependent on $P$, the size of the population being tested. It depends only on the quality parameters of the test, $\\mathit{Sn}$ and $\\mathit{Sp}$, and the prevalence, $p$. For a given test, only the prevalence will change over time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selctivity and Specificity Values\n",
    "\n",
    "It has been dificult to find specificity and sensitivity values for COVID-19 tests, or any rt-PCR tests; research papers rarely publish the values. Howver, there are a few reports for the values for serology tests, and a few reports of values for rt-PRC tests for the MERS-CoV virus. \n",
    "\n",
    "We can get values for an antibidy test for COVID-19 from a a recently published paper, _Development and Clinical Application of A Rapid IgM-IgG Combined Antibody Test for SARS-CoV-2 Infection Diagnosis_<sup><a href=\"#fnote2\" rel=\"noopener\" target=\"_self\">2</a></sup>, which reports: \n",
    "\n",
    "> The overall testing sensitivity was 88.66% and specificity was 90.63%\n",
    "\n",
    "This test is significantly different from the most common early tests for COVID-19; this test looks for antibodies in the patient's blood, while most COVID-19 tests are rt-PCR assays that look for fragments of RNA from the virus. \n",
    "\n",
    "The article _MERS-CoV diagnosis: An update._<sup><a href=\"#fnote4\" rel=\"noopener\" target=\"_self\">4</a></sup> reports that for MERS-CoV:\n",
    "\n",
    "> Song et al. developed a rapid immunochromatographic assay for the detection of MERS-CoV nucleocapsid protein from camel nasal swabs with 93.9% sensitivity and 100% specificity compared to RT-rtPCR\n",
    "\n",
    "The article _Performance Evaluation of the PowerChek MERS (upE & ORF1a) Real-Time PCR Kit for the Detection of Middle East Respiratory Syndrome Coronavirus RNA_<sup><a href=\"#fnote5\" rel=\"noopener\" target=\"_self\">5</a></sup> reports:\n",
    "\n",
    "> The diagnostic sensitivity and specificity of the PowerChek MERS assay were both 100% (95% confidence interval, 91.1–100%).\n",
    "\n",
    "The [Emergency Use Authorization for LabCorp's rt-PCR test](https://www.fda.gov/media/136151/download)<sup><a href=\"#fnote6\" rel=\"noopener\" target=\"_self\">6</a></sup> reports:\n",
    "\n",
    "~~~\n",
    "Performance of the COVID-19 RT-PCR test against the expected results [ with NP swabs ] are:\n",
    "Positive Percent Agreement 40/40 = 100% (95% CI: 91.24%-100%)\n",
    "Negative Percent Agreement 50/50 = 100% (95% CI: 92.87% -100%)\n",
    "~~~\n",
    "\n",
    "Using the lower bound of the 95% CI,  values convert to a specificity of .90  and sensitivity of .94.\n",
    "\n",
    "Based on these values, we'll explore the effects of sensitivity and specificities in the range of .9 to 1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPV For Serology Test\n",
    "\n",
    "First we'll look at the positive prediction value for the antibody test in reference (<a href=\"#fnote2\" rel=\"noopener\" target=\"_self\">2</a>), which has the lowest published Sp and Sn values at .9063 and .8866. The plot below shows the portion of positive test results that are true positives s a function of the prevalence. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_vs_tpr(Sp, Sn):\n",
    "\n",
    "    for p in np.power(10,np.linspace(-7,np.log10(.5), num=100)): # range from 1 per 10m to 50%\n",
    "        ppv = (p*Sn) / ( (p*Sn)+(1-p)*(1-Sp))\n",
    "        yield (p, ppv)\n",
    "\n",
    "def plot_ppv(Sp, Sn):\n",
    "\n",
    "    df = pd.DataFrame(list(p_vs_tpr(Sp, Sn)), columns='p ppv'.split())\n",
    "    df.head()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "    df.plot(ax=ax, x='p',y='ppv', figsize=(10,10))\n",
    "\n",
    "    fig.suptitle(f'Portion of Positives that Are True Vs Prevalence\\nFor test with Sp={Sp} and Sn={Sn}', fontsize=20)\n",
    "\n",
    "    ax.set_xlabel('Condition Prevalence in Portion of Tested Population', fontsize=18)\n",
    "    ax.set_ylabel('Portion of Positive Test Results that are True Positives', fontsize=18);\n",
    "\n",
    "\n",
    "    #ax.set_xscale('log')\n",
    "    #ax.set_yscale('log')\n",
    "    \n",
    "    \n",
    "plot_ppv(Sp = .9063, Sn = .8866)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important implication of this curve is that using a test with low Sp and Sn values in conditions of low prevalence will result in a very large portion of false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# False Positives for LabCorp's test\n",
    "\n",
    "Although the published results for the LabCorp test are 100% true positives and true negative rates, the 95% error margin is substantial, because the test was validatd with a relatively small number of samples. This analysis will use the published error margins to produce a distribution of positive prediction values. First, let's look at the distributions of the true positive and true negative rates, accounting for the published confidence intervals. These distributions are generated by converting the published true and false rates, and their CIs into gaussian distributions, and selecting only values that are 1 or lower from those distributions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CI to standard error\n",
    "p_se = (1-.9124) * 1.96\n",
    "n_se = (1-.9287) * 1.96\n",
    "\n",
    "\n",
    "def select_v(se):\n",
    "    \"\"\"get a distribution value, which must be less than or equal to 1\"\"\"\n",
    "    while True:\n",
    "        v = np.random.normal(1, se)\n",
    "        if v <= 1:\n",
    "            return v\n",
    "        \n",
    "    \n",
    "# These values are not TP and FP counts; they are normalized to \n",
    "# prevalence\n",
    "TP = np.array(list(select_v(p_se) for _ in range(2000)))\n",
    "TN = np.array(list(select_v(n_se) for _ in range(2000)))\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(12,8))\n",
    "sns.distplot( TP, ax=ax[0], kde=False);\n",
    "\n",
    "ax[0].set_title('Distribution of Posibile True Positives Rates');\n",
    "\n",
    "sns.distplot( TN, ax=ax[1], kde=False);\n",
    "\n",
    "ax[1].set_title('Distribution of Posibile True Negative Rates');\n",
    "\n",
    "fig.suptitle(f'Distribution of True Positive and Negative Rates'\n",
    "             '\\nFor published confidence intervals and 4K random samples', fontsize=20);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these distributions, we can calculate the distributions for the positive prediction value, the portion of all positive results that are true positives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these distributions, we can use ([Eq 2](#MathJax-Span-5239)) to compute the distributions of PPV for a variety of prevalences. In each chart, the 'mean' is the expectation value of the distribution, the weighted mean of the values. It is the most likely PPV valule for the given prevalence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = 1-TN\n",
    "FN = 1-TP\n",
    "\n",
    "Sn = TP / (TP+FN)\n",
    "Sp = TN / (TN+FP)\n",
    "\n",
    "def ppv_dist_ufunc(p, Sp, Sn):\n",
    "    return (p*Sn) / ( (p*Sn)+(1-p)*(1-Sp))\n",
    "\n",
    "def ppv_dist(p, Sp, Sn):\n",
    "    sp = np.random.choice(Sp, 10000, replace=True)\n",
    "    sn = np.random.choice(Sn, 10000, replace=True)\n",
    "    \n",
    "    return ppv_dist_ufunc(p,sp, sn)\n",
    "    \n",
    "fig, axes = plt.subplots( 2,2, figsize=(15,15))\n",
    "axes = axes.flat\n",
    "\n",
    "def plot_axis(axn, prevalence):\n",
    "    ppvd = ppv_dist(prevalence, Sp, Sn)\n",
    "    wmean = (ppvd.sum()/len(ppvd)).round(4)\n",
    "    sns.distplot( ppvd, ax=axes[axn], kde=False);\n",
    "    axes[axn].set_title(f' prevalence = {prevalence}, mean={wmean}');\n",
    "    axes[axn].set_xlabel('Positive Prediction Value (PPV)')\n",
    "    axes[axn].set_ylabel('PPV Frequency')\n",
    "\n",
    "plot_axis(0, .001)\n",
    "plot_axis(1, .01)\n",
    "plot_axis(2, .10)\n",
    "plot_axis(3, .5)\n",
    "    \n",
    "fig.suptitle(f'Distribution of PPV Values for LabCorp Test\\nBy condition prevalence', fontsize=20);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implication of these charts is that, even for a test with published true positive and true negative rate of 100%, the uncertainties in the measurements can mean that there still a substantial problem of false positives for low prevalences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the mean PPV value or a range of prevalence values results in the following relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppv_vs_p():\n",
    "    for p in np.power(10,np.linspace(-7,np.log10(1), num=100)): # range from 1 per 10m to 50%\n",
    "        ppvd = ppv_dist(p, Sp, Sn)\n",
    "        yield p, ppvd.sum()/len(ppvd)\n",
    "        \n",
    "ppv_v_p = pd.DataFrame(list(ppv_vs_p()), columns='p ppv'.split())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "sns.lineplot(x='p', y='ppv', data=ppv_v_p, ax=ax)\n",
    "ax.set_xlabel('Prevalence')\n",
    "ax.set_ylabel('Positive Predictive Value')\n",
    "\n",
    "fig.suptitle(\"Positive Predictive Value vs Prevalence\\nFor LabCorp Test\", fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this curve to the one presented earlier, for the antibody test with published sensitivity of 88.66% and specificity of 90.63%; The relationship between P and PPV for the rt-PCR test isn't much better. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Tests with less than 100% specificity and selectivity, including those with published values of 100% but with a moderate confidence interval, are very sensitive to low condition prevalences. Considering the confidence intervals, to ensure that 50% of positive results are true positives requires a prevalence of about 10%, and 80% PPV requires about a 30% prevalence. This suggests that using rt-PCR tests to test a large population that has a low prevalence is likely to produce a large number of false positive results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References \n",
    "\n",
    "* <a name=\"fnote1\">1</a> Parikh, Rajul et al. “[Understanding and using sensitivity, specificity and predictive values.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2636062/)” Indian journal of ophthalmology vol. 56,1 (2008): 45-50. doi:10.4103/0301-4738.37595\n",
    "* <a name=\"fnote2\">2</a> Li, Zhengtu et al. “[Development and Clinical Application of A Rapid IgM-IgG Combined Antibody Test for SARS-CoV-2 Infection Diagnosis.](https://pubmed.ncbi.nlm.nih.gov/32104917/)” Journal of medical virology, 10.1002/jmv.25727. 27 Feb. 2020, doi:10.1002/jmv.25727\n",
    "* <a name=\"fnote3\">3</a> Zhuang, G H et al. “[Potential False-Positive Rate Among the 'Asymptomatic Infected Individuals' in Close Contacts of COVID-19 Patients](https://pubmed.ncbi.nlm.nih.gov/32133832)” Zhonghua liuxingbingxue zazhi, vol. 41,4 485-488. 5 Mar. 2020, doi:10.3760/cma.j.cn112338-20200221-00144\n",
    "* <a name=\"fnote4\">4</a> Al Johani, Sameera, and Ali H Hajeer. “[MERS-CoV diagnosis: An update.](https://www.sciencedirect.com/science/article/pii/S1876034116300223)” Journal of infection and public health vol. 9,3 (2016): 216-9. doi:10.1016/j.jiph.2016.04.005\n",
    "* <a name=\"fnote5\">5</a> Huh, Hee Jae et al. “[Performance Evaluation of the PowerChek MERS (upE & ORF1a) Real-Time PCR Kit for the Detection of Middle East Respiratory Syndrome Coronavirus RNA.](http://www.annlabmed.org/journal/view.html?volume=37&number=6&spage=494)” Annals of laboratory medicine vol. 37,6 (2017): 494-498. doi:10.3343/alm.2017.37.6.494\n",
    "* <a name=\"fnote6\">6</a> [Emergency Use Authorization summary](https://www.fda.gov/media/136151/download) for LabCorp's COVID-19 rt-PCR test. \n",
    "\n",
    "\n",
    "The World Health Organization has a [web page with links to information the COVID-19 tests](https://www.who.int/emergencies/diseases/novel-coronavirus-2019/technical-guidance/laboratory-guidance) from many countries. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
